|  |  |  |  |
| --- | --- | --- | --- |
|  | \mathcal{C}\_{1}=\left\{\delta\_{\psi\_{1}}=\psi\_{1}\left(U\right)S\_{2};\ U=\frac% {S\_{1}}{S\_{2}},\ \mbox{$\psi\_{1}(.)$ is a positive function}\right\} |  | (17) |

and derive [38]-type estimators for \sigma\_{2}, which gives an improvement upon \delta\_{j2} for j=1,2 as we proved in the next theorem.

###### Theorem 6.

1. (i)

   Under the loss function L\_{1}(\cdot), the risk of the estimator

   |  |  |  |
   | --- | --- | --- |
   |  | \delta\_{2S1}^{1}(X,S)=\max\left\{\psi\_{1}(U),\psi\_{11}(U)\right\}S\_{2}, |  |

   is nowhere larger than that of the estimator \delta\_{\psi\_{1}} provided P\left(\psi\_{11}(U)>\psi\_{1}(U)\right)>0, where \psi\_{11}(U)=(1+U)\left(\frac{E(\tau)}{(p\_{1}+p\_{2}-2)(p\_{1}+p\_{2}-3)E(1/\tau)%
   }\right)^{1/2}.
2. (ii)

   For the loss function L\_{2}(\cdot), the risk of the estimator

   |  |  |  |
   | --- | --- | --- |
   |  | \delta\_{2S1}^{2}(X,S)=\max\left\{\psi\_{1}(U),\psi\_{12}(U)\right\}S\_{2}, |  |

   is nowhere larger than that of the estimator \delta\_{\psi\_{1}} provided P\left(\psi\_{12}(U)>\psi\_{1}(U)\right)>0, where \psi\_{12}(U)=\frac{(1+U)}{(p\_{1}+p\_{2}-2)E(\frac{1}{\tau})}.

Proof. Proof of this theorem is similar to the Theorem 1.

###### Remark 9.

If \tau=1 with probability one, then the Theorem 6 reduces to the following result which was previously obtained by [29] in Example 3.3 and Example 3.4 under entropy and symmetric loss functions respectively.

As in the previous section, we derive an improved estimator for \sigma\_{2} within the class of estimators \mathcal{C}\_{1} using the IERD method of [19]. We have the following theorem as follows

###### Theorem 7.

1. (i)

   Assume that the function \psi\_{1}(z) satisfies the following conditions:

   1. (a)

      \psi\_{1}(z) is non-decreasing in z and \lim\limits\_{z\rightarrow 0}\psi\_{1}(z)=\left(\frac{E(\tau)}{(p\_{2}-1)(p\_{2}-2%
      )E(1/\tau)}\right)^{1/2}
   2. (b)

      \psi\_{1}(z)\leq\psi\_{\*}^{1}(z)=\left(\frac{E(\tau)\left[\frac{B(p\_{1}-1,p\_{2}-%
      2)}{\Gamma(p\_{1}-1)}-B\left(\frac{z}{1+z};p\_{1}-1,p\_{2}-2\right)\right]}{E(1/%
      \tau)(p\_{1}+p\_{2}-2)(p\_{1}+p\_{2}-3)\left[\frac{B(p\_{1}-1,p\_{2})}{\Gamma(p\_{1}-%
      1)}-B\left(\frac{z}{1+z};p\_{1}-1,p\_{2}\right)\right]}\right)^{1/2}.

   Then the risk of the estimator \delta\_{\psi\_{1}} defined in (17) dominates \delta\_{12} under the loss function L\_{1}(\cdot).
2. (ii)

   Let \psi\_{1}(z) satisfies the following conditions:

   1. (a)

      \psi\_{1}(z) is non-decreasing in z and \lim\limits\_{z\rightarrow 0}\psi\_{1}(z)=\frac{1}{(p\_{2}-1)E\left(1/\tau\right)}
   2. (b)

      \psi\_{1}(z)\leq\psi\_{\*}^{2}(z)=\frac{\frac{B(p\_{1}-1,p\_{2}-1)}{\Gamma(p\_{1}-1)%
      }-B\left(\frac{z}{1+z};p\_{1}-1,p\_{2}-1\right)}{E(1/\tau)(p\_{1}+p\_{2}-2)\left[%
      \frac{B(p\_{1}-1,p\_{2})}{\Gamma(p\_{1}-1)}-B\left(\frac{z}{1+z};p\_{1},p\_{2}-1%
      \right)\right]}.

   Then the risk of the estimator \delta\_{\psi\_{1}} defined in (17) is nowhere larger than that of \delta\_{22} with respect to the L\_{2}(\cdot) loss function.

Proof. Proof of this theorem is similar to the Theorem 2.

###### Remark 10.

The boundary estimator \delta\_{\psi\_{\*}^{1}} and \delta\_{\psi\_{\*}^{2}} are [7]-type estimator for \sigma\_{2} under the loss functions L\_{1}(\cdot) and L\_{2}(\cdot) respectively.

###### Remark 11.

Now we prove that \delta\_{\psi\_{\*}^{1}} is a generalized Bayes estimator of \sigma\_{2} under the loss function L\_{1}(\cdot). We consider the prior distribution as

|  |  |  |
| --- | --- | --- |
|  | \pi(\sigma\_{1},\sigma\_{2},\mu\_{1},\mu\_{2})=\frac{1}{\sigma\_{1}\sigma\_{2}}I\_{% \sigma\_{1}\leq\sigma\_{2}}. |  |

The corresponding posterior distribution, for given \tau>0, is proportional to

|  |  |  |  |
| --- | --- | --- | --- |
|  | \pi(\sigma\_{1},\sigma\_{2},\mu\_{1},\mu\_{2}\big{|}X,S\_{1},Y,S\_{2})\propto\frac{% \tau^{p\_{1}+p\_{2}-2}}{\sigma\_{1}^{p\_{1}}\sigma\_{2}^{p\_{2}}}e^{-\frac{\tau S\_{1% }}{\sigma\_{1}}-\frac{\tau S\_{2}}{\sigma\_{2}}}\frac{p\_{1}\tau}{\sigma\_{1}}e^{-% \frac{p\_{1}\tau}{\sigma\_{1}}(X-\mu\_{1})}\frac{p\_{2}\tau}{\sigma\_{2}}e^{-\frac{% p\_{2}\tau}{\sigma\_{2}}(Y-\mu\_{2})}, |  | (18) |

where \mu\_{1}\leq x,\ \mu\_{2}\leq y,\ 0<\sigma\_{1}\leq\sigma\_{2}. For the symmetric loss function L\_{1}(\cdot), the generalized Bayes estimator of \sigma\_{2} is obtained as follows