Estimation of \sigma\_{1} and \sigma\_{2} under the square error loss function for multivariate Lomax distribution has been studied by [33], which is a special case of this work. Here we will derive the better estimator than \delta\_{{1i}} and \delta\_{{2i}} of \sigma\_{i} for multivariate Lomax distribution under the loss function L\_{1}(\cdot) and L\_{2}(\cdot) for i=1,2 respectively.
Now as an application of Theorem 1, 4 and 5 the [38]-type improved estimators of \sigma\_{1} are obtained for multivariate Lomax distribution as follows which is better than that of \delta\_{11} and \delta\_{12} under the loss function L\_{1}(\cdot) and L\_{2}(\cdot) respectively.

###### Theorem 10.

1. (i)

   Under L\_{1}(\cdot) loss function, we have \varphi\_{11}(W)=(1+W)\left(\frac{b(b-1)}{(p\_{1}+p\_{2}-2)(p\_{1}+p\_{2}-3)}\right%
   )^{\frac{1}{2}}, \varphi\_{21}(W,W\_{1})=(1+W+p\_{1}W\_{1})\left(\frac{b(b-1)}{(p\_{1}+p\_{2}-1)(p\_{1%
   }+p\_{2}-2)}\right)^{1/2}, \varphi\_{31}(W,W\_{2})=\frac{(1+W+p\_{2}W\_{2})\left(b(b-1)\right)^{1/2}}{\left((%
   p\_{1}+p\_{2}-1)(p\_{1}+p\_{2}-2)\right)^{1/2}} The improved estimator of \sigma\_{1} are obtained as follows

   |  |  |  |
   | --- | --- | --- |
   |  | \delta^{1}\_{11}(X,S)=\min\left\{\varphi\_{11}(W),\ c\_{1}\right\}S\_{1} |  |

   |  |  |  |
   | --- | --- | --- |
   |  | \delta\_{12}^{1}=\begin{cases}\min\left\{\varphi\_{21}(W,W\_{1}),c\_{1}\right\}S\_{% 1},&\ W\_{1}>0\\ c\_{1}S\_{1},&\text{otherwise}\end{cases} |  |

   |  |  |  |
   | --- | --- | --- |
   |  | \delta\_{13}^{1}=\begin{cases}\min\left\{\varphi\_{31}(W,W\_{2}),c\_{1}\right\}S\_{% 1},&\ W\_{2}>0\\ c\_{1}S\_{1},&\text{otherwise}\end{cases} |  |
2. (ii)

   Under the Stein loss function L\_{2}(\cdot) we have \varphi\_{12}(W)=(1+W)\frac{b-1}{(p\_{1}+p\_{2}-2)}, \varphi\_{22}(W,W\_{1})=(1+W+p\_{1}W\_{1})\frac{b-1}{p\_{1}+p\_{2}-1}, \varphi\_{32}(W,W\_{1})=(1+W+p\_{2}W\_{2})\frac{b-1}{p\_{1}+p\_{2}-1}. The improved estimators are obtained as follows

   |  |  |  |
   | --- | --- | --- |
   |  | \delta^{2}\_{11}(X,S)=\min\left\{\varphi\_{12}(W),d\_{1}\right\}S\_{1} |  |

   |  |  |  |
   | --- | --- | --- |
   |  | \delta\_{12}^{2}=\begin{cases}\min\left\{\varphi\_{22}(W,W\_{1}),d\_{1}\right\}S\_{% 1},&\ W\_{1}>0\\ d\_{1}S\_{1},&\text{otherwise}\end{cases} |  |

   |  |  |  |
   | --- | --- | --- |
   |  | \delta\_{13}^{2}=\begin{cases}\min\left\{\varphi\_{32}(W,W\_{2}),d\_{1}\right\}S\_{% 1},&\ W\_{2}>0\\ d\_{1}S\_{1},&\text{otherwise}\end{cases} |  |

If we use the both information X and Y, analogous result to Theorem 4 can be derived, as described in the following theorem.

###### Theorem 11.

1. (i)

   Under the loss function L\_{1}(\cdot) we have \varphi\_{41}(W,W\_{1},W\_{2})=(1+W+p\_{1}W\_{1}+p\_{2}W\_{2})\left(\frac{b(b-1)}{(p\_%
   {1}+p\_{2})(p\_{1}+p\_{2}-1)}\right)^{1/2}. The improved estimator of \sigma\_{1} is obtained as

   |  |  |  |
   | --- | --- | --- |
   |  | \delta\_{14}^{1}=\begin{cases}\min\left\{\varphi\_{41}(W,W\_{1},W\_{2}),c\_{1}% \right\}S\_{1},&\ W\_{1}>0,\ W\_{2}>0\\ c\_{1}S\_{1},&\text{otherwise}\end{cases} |  |
2. (ii)

   For the Stein type loss function L\_{2}(\cdot), we have \varphi\_{42}(W,W\_{1},W\_{2})=(1+W+p\_{1}W\_{1}+p\_{2}W\_{2})\frac{b-1}{p\_{1}+p\_{2}}. We get the improved estimators as

   |  |  |  |
   | --- | --- | --- |
   |  | \delta\_{14}^{2}=\begin{cases}\min\left\{\varphi\_{42}(W,W\_{1},W\_{2}),d\_{1}% \right\}S\_{1},&W\_{1}>0,\ W\_{2}>0\\ d\_{1}S\_{1},&\text{otherwise}\end{cases} |  |

As in the Theorem 2, the IERD method of [19] is applied for an estimator of the form (3). In that case we have the following theorem

###### Theorem 12.

1. (i)

   Under the loss function L\_{1}(\cdot), the risk of the estimator \delta\_{\varphi\_{1}} given in (3) is nowhere greater than that of \delta\_{{11}} provided the function \varphi\_{1}(w) satisfies